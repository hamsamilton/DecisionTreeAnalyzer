% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/tree_analyzer.R
\name{eval_metrics}
\alias{eval_metrics}
\title{Evaluate performance metrics for classification}
\usage{
eval_metrics(predictions, actuals)
}
\arguments{
\item{predictions}{A numeric or logical vector of predicted classes.}

\item{actuals}{A numeric or logical vector of actual classes.}
}
\value{
A list containing the following elements:
  * sensitivity: The proportion of actual positive cases that were correctly identified.
  * specificity: The proportion of actual negative cases that were correctly identified.
  * precision: The proportion of predicted positive cases that were correctly identified.
  * npv: The proportion of predicted negative cases that were correctly identified.
  * fpr: The proportion of actual negative cases that were incorrectly identified as positive.
  * fdr: The proportion of predicted positive cases that were incorrect.
  * fnr: The proportion of actual positive cases that were incorrectly identified as negative.
  * f1: The harmonic mean of precision and sensitivity.
  * accuracy: The proportion of total cases that were correctly identified.
}
\description{
This function calculates various performance metrics for binary classification, including
sensitivity, specificity, precision, negative predictive value (npv), false positive rate (fpr),
false discovery rate (fdr), false negative rate (fnr), F1 score, and accuracy.
}
\examples{
\dontrun{
results = eval_metrics(predicted_classes, actual_classes)
print(results)
}
}
